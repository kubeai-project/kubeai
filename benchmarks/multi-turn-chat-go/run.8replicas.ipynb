{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Turn Chat Benchmark\n",
    "\n",
    "```bash\n",
    "gcloud container clusters create-auto cluster-1 \\\n",
    "    --location=us-central1\n",
    "\n",
    "helm repo add kubeai https://www.kubeai.org\n",
    "helm repo update\n",
    "curl -L -O https://raw.githubusercontent.com/substratusai/kubeai/refs/heads/main/charts/kubeai/values-gke.yaml\n",
    "helm upgrade --install kubeai kubeai/kubeai \\\n",
    "    -f values-gke.yaml \\\n",
    "    --set secrets.huggingface.token=$HUGGING_FACE_HUB_TOKEN \\\n",
    "    --set metrics.prometheusOperator.vLLMPodMonitor.enabled=true \\\n",
    "    --set open-webui.enabled=false \\\n",
    "    --wait\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import run, PIPE\n",
    "import json\n",
    "from kubernetes import client, config, dynamic\n",
    "from kubernetes.client import api_client\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_config = config.load_kube_config()\n",
    "\n",
    "k8s_client = dynamic.DynamicClient(\n",
    "    api_client.ApiClient(configuration=k8s_config)\n",
    ")\n",
    "models_client = k8s_client.resources.get(api_version=\"kubeai.org/v1\", kind=\"Model\")\n",
    "\n",
    "v1 = client.CoreV1Api()\n",
    "\n",
    "namespace = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_pod_spec = {\n",
    "    \"apiVersion\": \"v1\",\n",
    "    \"kind\": \"Pod\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"bench\"\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"restartPolicy\": \"Never\",\n",
    "        \"containers\": [\n",
    "            {\n",
    "                \"name\": \"bench\",\n",
    "                \"image\": \"us-central1-docker.pkg.dev/substratus-dev/default/benchmark-multi-turn-chat-go:v0.1.1\",\n",
    "                \"imagePullPolicy\": \"Always\",\n",
    "                \"command\": [\"sleep\", \"infinity\"],\n",
    "                \"env\": [\n",
    "                    {\n",
    "                        \"name\": \"OPENAI_BASE_URL\",\n",
    "                        \"value\": \"http://kubeai/openai/v1\"\n",
    "                    }\n",
    "                ],\n",
    "                \"resources\": {\n",
    "                    \"requests\": {\n",
    "                        \"cpu\": \"2\",\n",
    "                        \"memory\": \"2G\"\n",
    "                    },\n",
    "                    \"limits\": {\n",
    "                        \"cpu\": \"2\",\n",
    "                        \"memory\": \"2G\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = {\n",
    "    \"apiVersion\": \"kubeai.org/v1\",\n",
    "    \"kind\": \"Model\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"bench\",\n",
    "        \"namespace\": \"default\",\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"features\": [\"TextGeneration\"],\n",
    "        \"url\": \"hf://neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8\",\n",
    "        \"engine\": \"VLLM\",\n",
    "        \"args\": [\n",
    "            \"--enable-prefix-caching\",\n",
    "            \"--max-model-len=16384\",\n",
    "            \"--max-num-batched-token=16384\",\n",
    "            \"--gpu-memory-utilization=0.90\",\n",
    "            \"--disable-log-requests\",\n",
    "        ],\n",
    "        \"resourceProfile\": \"nvidia-gpu-l4:1\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_k8s_service(model_name: str):\n",
    "    service_body = {\n",
    "        \"apiVersion\": \"v1\",\n",
    "        \"kind\": \"Service\",\n",
    "        \"metadata\": {\n",
    "            \"name\": f\"k8s-{model_name}\",\n",
    "            \"labels\": {\n",
    "                \"app\": f\"k8s-{model_name}\"\n",
    "            }\n",
    "        },\n",
    "        \"spec\": {\n",
    "            \"selector\": {\n",
    "                \"app.kubernetes.io/name\": \"vllm\",\n",
    "                \"model\": model_name\n",
    "            },\n",
    "            \"ports\": [\n",
    "                {\n",
    "                    \"name\": \"http\",\n",
    "                    \"protocol\": \"TCP\",\n",
    "                    \"port\": 80,\n",
    "                    \"targetPort\": 8000\n",
    "                }\n",
    "            ],\n",
    "            \"type\": \"ClusterIP\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return v1.create_namespaced_service(namespace=namespace, body=service_body)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "benches = [\n",
    "    {\n",
    "        \"thread_count\": 8000,\n",
    "        \"max_concurrent_threads\": 300,\n",
    "    },\n",
    "    {\n",
    "        \"thread_count\": 8000,\n",
    "        \"max_concurrent_threads\": 600,\n",
    "    },\n",
    "    {\n",
    "        \"thread_count\": 8000,\n",
    "        \"max_concurrent_threads\": 1200,\n",
    "    },\n",
    "    {\n",
    "        \"thread_count\": 8000,\n",
    "        \"max_concurrent_threads\": 2400,\n",
    "    },\n",
    "]\n",
    "specs = [\n",
    "    {\n",
    "        \"minReplicas\": 8,\n",
    "        \"maxReplicas\": 8,\n",
    "        \"loadBalancing\": {\n",
    "            \"strategy\": \"PrefixHash\",\n",
    "            \"prefixHash\": {\n",
    "                \"meanLoadFactor\": 125,\n",
    "                \"prefixCharLength\": 100,\n",
    "                \"replication\": 256,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"minReplicas\": 8,\n",
    "        \"maxReplicas\": 8,\n",
    "        \"loadBalancing\": {\n",
    "            \"strategy\": \"LeastLoad\",\n",
    "            \"prefixHash\": {\n",
    "                \"meanLoadFactor\": 125,\n",
    "                \"prefixCharLength\": 100,\n",
    "                \"replication\": 256,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {# k8s-native\n",
    "        \"minReplicas\": 8,\n",
    "        \"maxReplicas\": 8,\n",
    "    }\n",
    "] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bench={'thread_count': 8000, 'max_concurrent_threads': 300}, spec={'minReplicas': 8, 'maxReplicas': 8, 'loadBalancing': {'strategy': 'PrefixHash', 'prefixHash': {'meanLoadFactor': 125, 'prefixCharLength': 100, 'replication': 256}}}\n",
      "pod \"kubeai-74c9f949c4-p4w6q\" deleted\n",
      "pod \"open-webui-0\" deleted\n",
      "pod/kubeai-74c9f949c4-bg9fh condition met\n",
      "pod/open-webui-0 condition met\n",
      "pod/bench condition met\n",
      "model.kubeai.org/bench condition met\n",
      "kubectl exec bench -- bench --threads=./data/large-exact.json --thread-count=8000 --max-concurrent-threads=300 --request-model=bench --max-completion-tokens=40 --request-timeout=2m --seed=2 --format=json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 06:49:04 Shuffling dataset threads\n",
      "2025/02/25 06:49:04 Trimming dataset threads (9204) to specified thread count (8000)\n",
      "2025/02/25 06:49:04 Starting run...\n",
      "2025/02/25 06:59:08 Run completed, starting summarization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_thread_count': 8000, 'input_messages_per_thread': {'mean': 7.378875}, 'duration': '10m4.223126978s', 'request_count': 59031, 'request_duration': {'mean': '2.937449585s'}, 'chunks_per_request': {'mean': 38.87284647049855}, 'failed_threads': 0, 'run_output_throughput': 3797.7741955639362, 'run_total_throughput': 41521.1349580028, 'ttft': {'mean': '128.475449ms'}, 'itl': {'mean': '72.25189ms'}, 'prompt_tokens': 22793327, 'cached_prompt_tokens': 0, 'completion_tokens': 2294703, 'total_tokens': 25088030}\n",
      "pod \"bench\" deleted\n",
      "bench={'thread_count': 8000, 'max_concurrent_threads': 600}, spec={'minReplicas': 8, 'maxReplicas': 8, 'loadBalancing': {'strategy': 'PrefixHash', 'prefixHash': {'meanLoadFactor': 125, 'prefixCharLength': 100, 'replication': 256}}}\n",
      "pod \"kubeai-74c9f949c4-bg9fh\" deleted\n",
      "pod \"open-webui-0\" deleted\n",
      "pod/kubeai-74c9f949c4-rzh5j condition met\n",
      "pod/open-webui-0 condition met\n",
      "pod/bench condition met\n",
      "model.kubeai.org/bench condition met\n",
      "kubectl exec bench -- bench --threads=./data/large-exact.json --thread-count=8000 --max-concurrent-threads=600 --request-model=bench --max-completion-tokens=40 --request-timeout=2m --seed=2 --format=json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 07:02:00 Shuffling dataset threads\n",
      "2025/02/25 07:02:00 Trimming dataset threads (9204) to specified thread count (8000)\n",
      "2025/02/25 07:02:00 Starting run...\n",
      "2025/02/25 07:09:21 Run completed, starting summarization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_thread_count': 8000, 'input_messages_per_thread': {'mean': 7.378875}, 'duration': '7m20.304926648s', 'request_count': 59031, 'request_duration': {'mean': '4.117835214s'}, 'chunks_per_request': {'mean': 38.82454981281022}, 'failed_threads': 0, 'run_output_throughput': 5205.147299730788, 'run_total_throughput': 56932.5630554215, 'ttft': {'mean': '205.630098ms'}, 'itl': {'mean': '100.67815ms'}, 'prompt_tokens': 22775836, 'cached_prompt_tokens': 0, 'completion_tokens': 2291852, 'total_tokens': 25067688}\n",
      "pod \"bench\" deleted\n",
      "bench={'thread_count': 8000, 'max_concurrent_threads': 1200}, spec={'minReplicas': 8, 'maxReplicas': 8, 'loadBalancing': {'strategy': 'PrefixHash', 'prefixHash': {'meanLoadFactor': 125, 'prefixCharLength': 100, 'replication': 256}}}\n",
      "pod \"kubeai-74c9f949c4-rzh5j\" deleted\n",
      "pod \"open-webui-0\" deleted\n",
      "pod/kubeai-74c9f949c4-g44nb condition met\n",
      "pod/open-webui-0 condition met\n",
      "pod/bench condition met\n",
      "model.kubeai.org/bench condition met\n",
      "kubectl exec bench -- bench --threads=./data/large-exact.json --thread-count=8000 --max-concurrent-threads=1200 --request-model=bench --max-completion-tokens=40 --request-timeout=2m --seed=2 --format=json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 07:12:16 Shuffling dataset threads\n",
      "2025/02/25 07:12:16 Trimming dataset threads (9204) to specified thread count (8000)\n",
      "2025/02/25 07:12:16 Starting run...\n",
      "2025/02/25 07:18:05 Run completed, starting summarization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_thread_count': 8000, 'input_messages_per_thread': {'mean': 7.378875}, 'duration': '5m49.192117322s', 'request_count': 59031, 'request_duration': {'mean': '6.277021263s'}, 'chunks_per_request': {'mean': 38.85490674391421}, 'failed_threads': 0, 'run_output_throughput': 6568.430059619489, 'run_total_throughput': 71811.59240452346, 'ttft': {'mean': '386.049694ms'}, 'itl': {'mean': '151.420324ms'}, 'prompt_tokens': 22782398, 'cached_prompt_tokens': 0, 'completion_tokens': 2293644, 'total_tokens': 25076042}\n",
      "pod \"bench\" deleted\n",
      "bench={'thread_count': 8000, 'max_concurrent_threads': 2400}, spec={'minReplicas': 8, 'maxReplicas': 8, 'loadBalancing': {'strategy': 'PrefixHash', 'prefixHash': {'meanLoadFactor': 125, 'prefixCharLength': 100, 'replication': 256}}}\n",
      "pod \"kubeai-74c9f949c4-g44nb\" deleted\n",
      "pod \"open-webui-0\" deleted\n",
      "pod/kubeai-74c9f949c4-lmwxv condition met\n",
      "pod/open-webui-0 condition met\n",
      "pod/bench condition met\n",
      "model.kubeai.org/bench condition met\n",
      "kubectl exec bench -- bench --threads=./data/large-exact.json --thread-count=8000 --max-concurrent-threads=2400 --request-model=bench --max-completion-tokens=40 --request-timeout=2m --seed=2 --format=json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 07:20:53 Shuffling dataset threads\n",
      "2025/02/25 07:20:53 Trimming dataset threads (9204) to specified thread count (8000)\n",
      "2025/02/25 07:20:53 Starting run...\n",
      "2025/02/25 07:30:50 Run completed, starting summarization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_thread_count': 8000, 'input_messages_per_thread': {'mean': 7.378875}, 'duration': '9m56.670071664s', 'request_count': 59031, 'request_duration': {'mean': '20.759292618s'}, 'chunks_per_request': {'mean': 38.83127509274788}, 'failed_threads': 0, 'run_output_throughput': 3843.13896221578, 'run_total_throughput': 42032.4819209684, 'ttft': {'mean': '12.581182145s'}, 'itl': {'mean': '209.408459ms'}, 'prompt_tokens': 22786438, 'cached_prompt_tokens': 0, 'completion_tokens': 2293086, 'total_tokens': 25079524}\n",
      "pod \"bench\" deleted\n",
      "bench={'thread_count': 8000, 'max_concurrent_threads': 300}, spec={'minReplicas': 8, 'maxReplicas': 8, 'loadBalancing': {'strategy': 'LeastLoad', 'prefixHash': {'meanLoadFactor': 125, 'prefixCharLength': 100, 'replication': 256}}}\n",
      "pod \"kubeai-74c9f949c4-lmwxv\" deleted\n",
      "pod \"open-webui-0\" deleted\n",
      "pod/kubeai-74c9f949c4-z5xb6 condition met\n",
      "pod/open-webui-0 condition met\n",
      "pod/bench condition met\n",
      "model.kubeai.org/bench condition met\n",
      "kubectl exec bench -- bench --threads=./data/large-exact.json --thread-count=8000 --max-concurrent-threads=300 --request-model=bench --max-completion-tokens=40 --request-timeout=2m --seed=2 --format=json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 07:33:36 Shuffling dataset threads\n",
      "2025/02/25 07:33:36 Trimming dataset threads (9204) to specified thread count (8000)\n",
      "2025/02/25 07:33:36 Starting run...\n",
      "2025/02/25 07:44:36 Run completed, starting summarization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_thread_count': 8000, 'input_messages_per_thread': {'mean': 7.378875}, 'duration': '10m59.819368534s', 'request_count': 59031, 'request_duration': {'mean': '3.198727361s'}, 'chunks_per_request': {'mean': 38.855702935745626}, 'failed_threads': 0, 'run_output_throughput': 3476.240785559492, 'run_total_throughput': 38004.916490577125, 'ttft': {'mean': '211.513933ms'}, 'itl': {'mean': '76.923279ms'}, 'prompt_tokens': 22782689, 'cached_prompt_tokens': 0, 'completion_tokens': 2293691, 'total_tokens': 25076380}\n",
      "pod \"bench\" deleted\n",
      "bench={'thread_count': 8000, 'max_concurrent_threads': 600}, spec={'minReplicas': 8, 'maxReplicas': 8, 'loadBalancing': {'strategy': 'LeastLoad', 'prefixHash': {'meanLoadFactor': 125, 'prefixCharLength': 100, 'replication': 256}}}\n",
      "pod \"kubeai-74c9f949c4-z5xb6\" deleted\n",
      "pod \"open-webui-0\" deleted\n",
      "pod/kubeai-74c9f949c4-gk2c8 condition met\n",
      "pod/open-webui-0 condition met\n",
      "pod/bench condition met\n",
      "model.kubeai.org/bench condition met\n",
      "kubectl exec bench -- bench --threads=./data/large-exact.json --thread-count=8000 --max-concurrent-threads=600 --request-model=bench --max-completion-tokens=40 --request-timeout=2m --seed=2 --format=json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 07:47:31 Shuffling dataset threads\n",
      "2025/02/25 07:47:31 Trimming dataset threads (9204) to specified thread count (8000)\n",
      "2025/02/25 07:47:31 Starting run...\n",
      "2025/02/25 07:55:29 Run completed, starting summarization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_thread_count': 8000, 'input_messages_per_thread': {'mean': 7.378875}, 'duration': '7m58.500736269s', 'request_count': 59031, 'request_duration': {'mean': '4.492309617s'}, 'chunks_per_request': {'mean': 38.81702834104115}, 'failed_threads': 0, 'run_output_throughput': 4788.724084035334, 'run_total_throughput': 52380.64040492846, 'ttft': {'mean': '319.854104ms'}, 'itl': {'mean': '107.296883ms'}, 'prompt_tokens': 22772767, 'cached_prompt_tokens': 0, 'completion_tokens': 2291408, 'total_tokens': 25064175}\n",
      "pod \"bench\" deleted\n",
      "bench={'thread_count': 8000, 'max_concurrent_threads': 1200}, spec={'minReplicas': 8, 'maxReplicas': 8, 'loadBalancing': {'strategy': 'LeastLoad', 'prefixHash': {'meanLoadFactor': 125, 'prefixCharLength': 100, 'replication': 256}}}\n",
      "pod \"kubeai-74c9f949c4-gk2c8\" deleted\n",
      "pod \"open-webui-0\" deleted\n",
      "pod/kubeai-74c9f949c4-2d2wc condition met\n",
      "pod/open-webui-0 condition met\n",
      "pod/bench condition met\n",
      "model.kubeai.org/bench condition met\n",
      "kubectl exec bench -- bench --threads=./data/large-exact.json --thread-count=8000 --max-concurrent-threads=1200 --request-model=bench --max-completion-tokens=40 --request-timeout=2m --seed=2 --format=json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 07:58:10 Shuffling dataset threads\n",
      "2025/02/25 07:58:10 Trimming dataset threads (9204) to specified thread count (8000)\n",
      "2025/02/25 07:58:10 Starting run...\n",
      "2025/02/25 08:05:13 Run completed, starting summarization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_thread_count': 8000, 'input_messages_per_thread': {'mean': 7.378875}, 'duration': '7m3.248768503s', 'request_count': 59031, 'request_duration': {'mean': '7.700969458s'}, 'chunks_per_request': {'mean': 38.861784486117465}, 'failed_threads': 0, 'run_output_throughput': 5420.098463874773, 'run_total_throughput': 59273.60660429701, 'ttft': {'mean': '1.196032821s'}, 'itl': {'mean': '166.676473ms'}, 'prompt_tokens': 22793431, 'cached_prompt_tokens': 0, 'completion_tokens': 2294050, 'total_tokens': 25087481}\n",
      "pod \"bench\" deleted\n",
      "bench={'thread_count': 8000, 'max_concurrent_threads': 2400}, spec={'minReplicas': 8, 'maxReplicas': 8, 'loadBalancing': {'strategy': 'LeastLoad', 'prefixHash': {'meanLoadFactor': 125, 'prefixCharLength': 100, 'replication': 256}}}\n",
      "pod \"kubeai-74c9f949c4-2d2wc\" deleted\n",
      "pod \"open-webui-0\" deleted\n",
      "pod/kubeai-74c9f949c4-grnsp condition met\n",
      "pod/open-webui-0 condition met\n",
      "pod/bench condition met\n",
      "model.kubeai.org/bench condition met\n",
      "kubectl exec bench -- bench --threads=./data/large-exact.json --thread-count=8000 --max-concurrent-threads=2400 --request-model=bench --max-completion-tokens=40 --request-timeout=2m --seed=2 --format=json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 08:08:02 Shuffling dataset threads\n",
      "2025/02/25 08:08:02 Trimming dataset threads (9204) to specified thread count (8000)\n",
      "2025/02/25 08:08:02 Starting run...\n",
      "2025/02/25 08:18:31 Run completed, starting summarization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_thread_count': 8000, 'input_messages_per_thread': {'mean': 7.378875}, 'duration': '10m28.610653736s', 'request_count': 59031, 'request_duration': {'mean': '22.568652072s'}, 'chunks_per_request': {'mean': 38.78323253883553}, 'failed_threads': 0, 'run_output_throughput': 3643.757843407395, 'run_total_throughput': 39866.51013796651, 'ttft': {'mean': '12.912108233s'}, 'itl': {'mean': '245.956753ms'}, 'prompt_tokens': 22770008, 'cached_prompt_tokens': 0, 'completion_tokens': 2290505, 'total_tokens': 25060513}\n",
      "pod \"bench\" deleted\n",
      "bench={'thread_count': 8000, 'max_concurrent_threads': 300}, spec={'minReplicas': 8, 'maxReplicas': 8}\n",
      "pod \"kubeai-74c9f949c4-grnsp\" deleted\n",
      "pod \"open-webui-0\" deleted\n",
      "pod/kubeai-74c9f949c4-fw497 condition met\n",
      "pod/open-webui-0 condition met\n",
      "pod/bench condition met\n",
      "model.kubeai.org/bench condition met\n",
      "kubectl exec bench -- bench --threads=./data/large-exact.json --thread-count=8000 --max-concurrent-threads=300 --request-model=bench --max-completion-tokens=40 --request-timeout=2m --seed=2 --format=json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 08:22:42 Shuffling dataset threads\n",
      "2025/02/25 08:22:42 Trimming dataset threads (9204) to specified thread count (8000)\n",
      "2025/02/25 08:22:42 Starting run...\n",
      "2025/02/25 08:34:11 Run completed, starting summarization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_thread_count': 8000, 'input_messages_per_thread': {'mean': 7.378875}, 'duration': '11m29.178892398s', 'request_count': 59031, 'request_duration': {'mean': '3.353627549s'}, 'chunks_per_request': {'mean': 38.85272145144077}, 'failed_threads': 0, 'run_output_throughput': 3327.8950143404822, 'run_total_throughput': 36395.055444493744, 'ttft': {'mean': '126.940244ms'}, 'itl': {'mean': '83.082534ms'}, 'prompt_tokens': 22789189, 'cached_prompt_tokens': 0, 'completion_tokens': 2293515, 'total_tokens': 25082704}\n",
      "pod \"bench\" deleted\n",
      "bench={'thread_count': 8000, 'max_concurrent_threads': 600}, spec={'minReplicas': 8, 'maxReplicas': 8}\n",
      "pod \"kubeai-74c9f949c4-fw497\" deleted\n",
      "pod \"open-webui-0\" deleted\n",
      "pod/kubeai-74c9f949c4-w24wf condition met\n",
      "pod/open-webui-0 condition met\n",
      "pod/bench condition met\n",
      "model.kubeai.org/bench condition met\n",
      "kubectl exec bench -- bench --threads=./data/large-exact.json --thread-count=8000 --max-concurrent-threads=600 --request-model=bench --max-completion-tokens=40 --request-timeout=2m --seed=2 --format=json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 08:36:59 Shuffling dataset threads\n",
      "2025/02/25 08:36:59 Trimming dataset threads (9204) to specified thread count (8000)\n",
      "2025/02/25 08:36:59 Starting run...\n",
      "2025/02/25 08:49:03 Run completed, starting summarization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_thread_count': 8000, 'input_messages_per_thread': {'mean': 7.378875}, 'duration': '12m4.07344713s', 'request_count': 59031, 'request_duration': {'mean': '6.802742698s'}, 'chunks_per_request': {'mean': 38.871254086835734}, 'failed_threads': 0, 'run_output_throughput': 3169.184022830223, 'run_total_throughput': 34654.71368886544, 'ttft': {'mean': '2.264357412s'}, 'itl': {'mean': '115.110403ms'}, 'prompt_tokens': 22797836, 'cached_prompt_tokens': 0, 'completion_tokens': 2294722, 'total_tokens': 25092558}\n",
      "pod \"bench\" deleted\n",
      "bench={'thread_count': 8000, 'max_concurrent_threads': 1200}, spec={'minReplicas': 8, 'maxReplicas': 8}\n",
      "pod \"kubeai-74c9f949c4-w24wf\" deleted\n",
      "pod \"open-webui-0\" deleted\n",
      "pod/kubeai-74c9f949c4-6fr99 condition met\n",
      "pod/open-webui-0 condition met\n",
      "pod/bench condition met\n",
      "model.kubeai.org/bench condition met\n",
      "kubectl exec bench -- bench --threads=./data/large-exact.json --thread-count=8000 --max-concurrent-threads=1200 --request-model=bench --max-completion-tokens=40 --request-timeout=2m --seed=2 --format=json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 08:51:51 Shuffling dataset threads\n",
      "2025/02/25 08:51:51 Trimming dataset threads (9204) to specified thread count (8000)\n",
      "2025/02/25 08:51:51 Starting run...\n",
      "2025/02/25 09:05:04 Run completed, starting summarization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_thread_count': 8000, 'input_messages_per_thread': {'mean': 7.378875}, 'duration': '13m13.186348355s', 'request_count': 59031, 'request_duration': {'mean': '13.934835229s'}, 'chunks_per_request': {'mean': 38.85734614016364}, 'failed_threads': 0, 'run_output_throughput': 2892.2169484607207, 'run_total_throughput': 31625.46865818341, 'ttft': {'mean': '8.481505257s'}, 'itl': {'mean': '140.334721ms'}, 'prompt_tokens': 22790823, 'cached_prompt_tokens': 0, 'completion_tokens': 2294067, 'total_tokens': 25084890}\n",
      "pod \"bench\" deleted\n",
      "bench={'thread_count': 8000, 'max_concurrent_threads': 2400}, spec={'minReplicas': 8, 'maxReplicas': 8}\n",
      "pod \"kubeai-74c9f949c4-6fr99\" deleted\n",
      "pod \"open-webui-0\" deleted\n",
      "pod/kubeai-74c9f949c4-nkz5f condition met\n",
      "pod/open-webui-0 condition met\n",
      "pod/bench condition met\n",
      "model.kubeai.org/bench condition met\n",
      "kubectl exec bench -- bench --threads=./data/large-exact.json --thread-count=8000 --max-concurrent-threads=2400 --request-model=bench --max-completion-tokens=40 --request-timeout=2m --seed=2 --format=json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 09:07:59 Shuffling dataset threads\n",
      "2025/02/25 09:07:59 Trimming dataset threads (9204) to specified thread count (8000)\n",
      "2025/02/25 09:07:59 Starting run...\n",
      "2025/02/25 09:16:38 Thread[6524/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[4927/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[3579/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[636/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[2089/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6525/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[5083/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[4970/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[278/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[1240/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[1041/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[1735/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[739/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6546/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[2254/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6548/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[3859/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[2155/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6541/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[290/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6547/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6544/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[2141/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[3818/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[683/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[4888/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[2369/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[890/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[339/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[4913/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[1773/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6549/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[5009/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6550/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[1988/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6542/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[4912/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[4997/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[2053/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[2162/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[5107/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[3886/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6552/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6551/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[631/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[1098/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6553/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[261/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6554/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[4897/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[1657/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[533/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6555/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[6561/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[508/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:38 Thread[2140/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5174/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[6807/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5175/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[3965/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[6803/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5179/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5379/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[4009/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[39/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[4006/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[6804/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[3987/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[6805/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[6813/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5040/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5180/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[1284/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[647/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[4012/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[6809/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[1117/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[2619/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5167/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[6814/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[6806/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[863/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[2553/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5191/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[1874/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[4058/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[1486/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5177/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[2150/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[6818/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[6820/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[344/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[1968/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5105/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[6819/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[6816/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5171/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[3294/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5192/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5389/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[4050/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[1005/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[2182/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[2024/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5267/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[749/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[1752/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[5166/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[6817/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[3842/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[1302/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:57 Thread[6644/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:58 Thread[4321/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:58 Thread[5307/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:58 Thread[6748/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:16:59 Thread[6283/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:17:00 Thread[6834/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:17:00 Thread[6305/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:17:01 Thread[6431/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:17:01 Thread[6643/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:17:02 Thread[6766/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:17:02 Thread[6508/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:17:41 Thread[7203/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:17:42 Thread[7339/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:17:42 Thread[7377/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:17:42 Thread[7021/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:17:43 Thread[5967/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:18:02 Thread[4626/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:18:02 Thread[7591/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:18:02 Thread[7473/8000]: Failed: stream: context deadline exceeded (Client.Timeout or context cancellation while reading body)\n",
      "2025/02/25 09:22:54 Run completed, starting summarization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_thread_count': 8000, 'input_messages_per_thread': {'mean': 7.378875}, 'duration': '14m54.733349231s', 'request_count': 58526, 'request_duration': {'mean': '27.65277817s'}, 'chunks_per_request': {'mean': 38.460256979803845}, 'failed_threads': 130, 'run_output_throughput': 2515.9998807854918, 'run_total_throughput': 27507.218794463235, 'ttft': {'mean': '21.44959869s'}, 'itl': {'mean': '158.817814ms'}, 'prompt_tokens': 22360477, 'cached_prompt_tokens': 0, 'completion_tokens': 2251149, 'total_tokens': 24611626}\n",
      "pod \"bench\" deleted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'spec': {'minReplicas': 8,\n",
       "   'maxReplicas': 8,\n",
       "   'loadBalancing': {'strategy': 'PrefixHash',\n",
       "    'prefixHash': {'meanLoadFactor': 125,\n",
       "     'prefixCharLength': 100,\n",
       "     'replication': 256}}},\n",
       "  'bench': {'thread_count': 8000, 'max_concurrent_threads': 300},\n",
       "  'result': {'input_thread_count': 8000,\n",
       "   'input_messages_per_thread': {'mean': 7.378875},\n",
       "   'duration': '10m4.223126978s',\n",
       "   'request_count': 59031,\n",
       "   'request_duration': {'mean': '2.937449585s'},\n",
       "   'chunks_per_request': {'mean': 38.87284647049855},\n",
       "   'failed_threads': 0,\n",
       "   'run_output_throughput': 3797.7741955639362,\n",
       "   'run_total_throughput': 41521.1349580028,\n",
       "   'ttft': {'mean': '128.475449ms'},\n",
       "   'itl': {'mean': '72.25189ms'},\n",
       "   'prompt_tokens': 22793327,\n",
       "   'cached_prompt_tokens': 0,\n",
       "   'completion_tokens': 2294703,\n",
       "   'total_tokens': 25088030}},\n",
       " {'spec': {'minReplicas': 8,\n",
       "   'maxReplicas': 8,\n",
       "   'loadBalancing': {'strategy': 'PrefixHash',\n",
       "    'prefixHash': {'meanLoadFactor': 125,\n",
       "     'prefixCharLength': 100,\n",
       "     'replication': 256}}},\n",
       "  'bench': {'thread_count': 8000, 'max_concurrent_threads': 600},\n",
       "  'result': {'input_thread_count': 8000,\n",
       "   'input_messages_per_thread': {'mean': 7.378875},\n",
       "   'duration': '7m20.304926648s',\n",
       "   'request_count': 59031,\n",
       "   'request_duration': {'mean': '4.117835214s'},\n",
       "   'chunks_per_request': {'mean': 38.82454981281022},\n",
       "   'failed_threads': 0,\n",
       "   'run_output_throughput': 5205.147299730788,\n",
       "   'run_total_throughput': 56932.5630554215,\n",
       "   'ttft': {'mean': '205.630098ms'},\n",
       "   'itl': {'mean': '100.67815ms'},\n",
       "   'prompt_tokens': 22775836,\n",
       "   'cached_prompt_tokens': 0,\n",
       "   'completion_tokens': 2291852,\n",
       "   'total_tokens': 25067688}},\n",
       " {'spec': {'minReplicas': 8,\n",
       "   'maxReplicas': 8,\n",
       "   'loadBalancing': {'strategy': 'PrefixHash',\n",
       "    'prefixHash': {'meanLoadFactor': 125,\n",
       "     'prefixCharLength': 100,\n",
       "     'replication': 256}}},\n",
       "  'bench': {'thread_count': 8000, 'max_concurrent_threads': 1200},\n",
       "  'result': {'input_thread_count': 8000,\n",
       "   'input_messages_per_thread': {'mean': 7.378875},\n",
       "   'duration': '5m49.192117322s',\n",
       "   'request_count': 59031,\n",
       "   'request_duration': {'mean': '6.277021263s'},\n",
       "   'chunks_per_request': {'mean': 38.85490674391421},\n",
       "   'failed_threads': 0,\n",
       "   'run_output_throughput': 6568.430059619489,\n",
       "   'run_total_throughput': 71811.59240452346,\n",
       "   'ttft': {'mean': '386.049694ms'},\n",
       "   'itl': {'mean': '151.420324ms'},\n",
       "   'prompt_tokens': 22782398,\n",
       "   'cached_prompt_tokens': 0,\n",
       "   'completion_tokens': 2293644,\n",
       "   'total_tokens': 25076042}},\n",
       " {'spec': {'minReplicas': 8,\n",
       "   'maxReplicas': 8,\n",
       "   'loadBalancing': {'strategy': 'PrefixHash',\n",
       "    'prefixHash': {'meanLoadFactor': 125,\n",
       "     'prefixCharLength': 100,\n",
       "     'replication': 256}}},\n",
       "  'bench': {'thread_count': 8000, 'max_concurrent_threads': 2400},\n",
       "  'result': {'input_thread_count': 8000,\n",
       "   'input_messages_per_thread': {'mean': 7.378875},\n",
       "   'duration': '9m56.670071664s',\n",
       "   'request_count': 59031,\n",
       "   'request_duration': {'mean': '20.759292618s'},\n",
       "   'chunks_per_request': {'mean': 38.83127509274788},\n",
       "   'failed_threads': 0,\n",
       "   'run_output_throughput': 3843.13896221578,\n",
       "   'run_total_throughput': 42032.4819209684,\n",
       "   'ttft': {'mean': '12.581182145s'},\n",
       "   'itl': {'mean': '209.408459ms'},\n",
       "   'prompt_tokens': 22786438,\n",
       "   'cached_prompt_tokens': 0,\n",
       "   'completion_tokens': 2293086,\n",
       "   'total_tokens': 25079524}},\n",
       " {'spec': {'minReplicas': 8,\n",
       "   'maxReplicas': 8,\n",
       "   'loadBalancing': {'strategy': 'LeastLoad',\n",
       "    'prefixHash': {'meanLoadFactor': 125,\n",
       "     'prefixCharLength': 100,\n",
       "     'replication': 256}}},\n",
       "  'bench': {'thread_count': 8000, 'max_concurrent_threads': 300},\n",
       "  'result': {'input_thread_count': 8000,\n",
       "   'input_messages_per_thread': {'mean': 7.378875},\n",
       "   'duration': '10m59.819368534s',\n",
       "   'request_count': 59031,\n",
       "   'request_duration': {'mean': '3.198727361s'},\n",
       "   'chunks_per_request': {'mean': 38.855702935745626},\n",
       "   'failed_threads': 0,\n",
       "   'run_output_throughput': 3476.240785559492,\n",
       "   'run_total_throughput': 38004.916490577125,\n",
       "   'ttft': {'mean': '211.513933ms'},\n",
       "   'itl': {'mean': '76.923279ms'},\n",
       "   'prompt_tokens': 22782689,\n",
       "   'cached_prompt_tokens': 0,\n",
       "   'completion_tokens': 2293691,\n",
       "   'total_tokens': 25076380}},\n",
       " {'spec': {'minReplicas': 8,\n",
       "   'maxReplicas': 8,\n",
       "   'loadBalancing': {'strategy': 'LeastLoad',\n",
       "    'prefixHash': {'meanLoadFactor': 125,\n",
       "     'prefixCharLength': 100,\n",
       "     'replication': 256}}},\n",
       "  'bench': {'thread_count': 8000, 'max_concurrent_threads': 600},\n",
       "  'result': {'input_thread_count': 8000,\n",
       "   'input_messages_per_thread': {'mean': 7.378875},\n",
       "   'duration': '7m58.500736269s',\n",
       "   'request_count': 59031,\n",
       "   'request_duration': {'mean': '4.492309617s'},\n",
       "   'chunks_per_request': {'mean': 38.81702834104115},\n",
       "   'failed_threads': 0,\n",
       "   'run_output_throughput': 4788.724084035334,\n",
       "   'run_total_throughput': 52380.64040492846,\n",
       "   'ttft': {'mean': '319.854104ms'},\n",
       "   'itl': {'mean': '107.296883ms'},\n",
       "   'prompt_tokens': 22772767,\n",
       "   'cached_prompt_tokens': 0,\n",
       "   'completion_tokens': 2291408,\n",
       "   'total_tokens': 25064175}},\n",
       " {'spec': {'minReplicas': 8,\n",
       "   'maxReplicas': 8,\n",
       "   'loadBalancing': {'strategy': 'LeastLoad',\n",
       "    'prefixHash': {'meanLoadFactor': 125,\n",
       "     'prefixCharLength': 100,\n",
       "     'replication': 256}}},\n",
       "  'bench': {'thread_count': 8000, 'max_concurrent_threads': 1200},\n",
       "  'result': {'input_thread_count': 8000,\n",
       "   'input_messages_per_thread': {'mean': 7.378875},\n",
       "   'duration': '7m3.248768503s',\n",
       "   'request_count': 59031,\n",
       "   'request_duration': {'mean': '7.700969458s'},\n",
       "   'chunks_per_request': {'mean': 38.861784486117465},\n",
       "   'failed_threads': 0,\n",
       "   'run_output_throughput': 5420.098463874773,\n",
       "   'run_total_throughput': 59273.60660429701,\n",
       "   'ttft': {'mean': '1.196032821s'},\n",
       "   'itl': {'mean': '166.676473ms'},\n",
       "   'prompt_tokens': 22793431,\n",
       "   'cached_prompt_tokens': 0,\n",
       "   'completion_tokens': 2294050,\n",
       "   'total_tokens': 25087481}},\n",
       " {'spec': {'minReplicas': 8,\n",
       "   'maxReplicas': 8,\n",
       "   'loadBalancing': {'strategy': 'LeastLoad',\n",
       "    'prefixHash': {'meanLoadFactor': 125,\n",
       "     'prefixCharLength': 100,\n",
       "     'replication': 256}}},\n",
       "  'bench': {'thread_count': 8000, 'max_concurrent_threads': 2400},\n",
       "  'result': {'input_thread_count': 8000,\n",
       "   'input_messages_per_thread': {'mean': 7.378875},\n",
       "   'duration': '10m28.610653736s',\n",
       "   'request_count': 59031,\n",
       "   'request_duration': {'mean': '22.568652072s'},\n",
       "   'chunks_per_request': {'mean': 38.78323253883553},\n",
       "   'failed_threads': 0,\n",
       "   'run_output_throughput': 3643.757843407395,\n",
       "   'run_total_throughput': 39866.51013796651,\n",
       "   'ttft': {'mean': '12.912108233s'},\n",
       "   'itl': {'mean': '245.956753ms'},\n",
       "   'prompt_tokens': 22770008,\n",
       "   'cached_prompt_tokens': 0,\n",
       "   'completion_tokens': 2290505,\n",
       "   'total_tokens': 25060513}},\n",
       " {'spec': {'minReplicas': 8, 'maxReplicas': 8},\n",
       "  'bench': {'thread_count': 8000, 'max_concurrent_threads': 300},\n",
       "  'result': {'input_thread_count': 8000,\n",
       "   'input_messages_per_thread': {'mean': 7.378875},\n",
       "   'duration': '11m29.178892398s',\n",
       "   'request_count': 59031,\n",
       "   'request_duration': {'mean': '3.353627549s'},\n",
       "   'chunks_per_request': {'mean': 38.85272145144077},\n",
       "   'failed_threads': 0,\n",
       "   'run_output_throughput': 3327.8950143404822,\n",
       "   'run_total_throughput': 36395.055444493744,\n",
       "   'ttft': {'mean': '126.940244ms'},\n",
       "   'itl': {'mean': '83.082534ms'},\n",
       "   'prompt_tokens': 22789189,\n",
       "   'cached_prompt_tokens': 0,\n",
       "   'completion_tokens': 2293515,\n",
       "   'total_tokens': 25082704}},\n",
       " {'spec': {'minReplicas': 8, 'maxReplicas': 8},\n",
       "  'bench': {'thread_count': 8000, 'max_concurrent_threads': 600},\n",
       "  'result': {'input_thread_count': 8000,\n",
       "   'input_messages_per_thread': {'mean': 7.378875},\n",
       "   'duration': '12m4.07344713s',\n",
       "   'request_count': 59031,\n",
       "   'request_duration': {'mean': '6.802742698s'},\n",
       "   'chunks_per_request': {'mean': 38.871254086835734},\n",
       "   'failed_threads': 0,\n",
       "   'run_output_throughput': 3169.184022830223,\n",
       "   'run_total_throughput': 34654.71368886544,\n",
       "   'ttft': {'mean': '2.264357412s'},\n",
       "   'itl': {'mean': '115.110403ms'},\n",
       "   'prompt_tokens': 22797836,\n",
       "   'cached_prompt_tokens': 0,\n",
       "   'completion_tokens': 2294722,\n",
       "   'total_tokens': 25092558}},\n",
       " {'spec': {'minReplicas': 8, 'maxReplicas': 8},\n",
       "  'bench': {'thread_count': 8000, 'max_concurrent_threads': 1200},\n",
       "  'result': {'input_thread_count': 8000,\n",
       "   'input_messages_per_thread': {'mean': 7.378875},\n",
       "   'duration': '13m13.186348355s',\n",
       "   'request_count': 59031,\n",
       "   'request_duration': {'mean': '13.934835229s'},\n",
       "   'chunks_per_request': {'mean': 38.85734614016364},\n",
       "   'failed_threads': 0,\n",
       "   'run_output_throughput': 2892.2169484607207,\n",
       "   'run_total_throughput': 31625.46865818341,\n",
       "   'ttft': {'mean': '8.481505257s'},\n",
       "   'itl': {'mean': '140.334721ms'},\n",
       "   'prompt_tokens': 22790823,\n",
       "   'cached_prompt_tokens': 0,\n",
       "   'completion_tokens': 2294067,\n",
       "   'total_tokens': 25084890}},\n",
       " {'spec': {'minReplicas': 8, 'maxReplicas': 8},\n",
       "  'bench': {'thread_count': 8000, 'max_concurrent_threads': 2400},\n",
       "  'result': {'input_thread_count': 8000,\n",
       "   'input_messages_per_thread': {'mean': 7.378875},\n",
       "   'duration': '14m54.733349231s',\n",
       "   'request_count': 58526,\n",
       "   'request_duration': {'mean': '27.65277817s'},\n",
       "   'chunks_per_request': {'mean': 38.460256979803845},\n",
       "   'failed_threads': 130,\n",
       "   'run_output_throughput': 2515.9998807854918,\n",
       "   'run_total_throughput': 27507.218794463235,\n",
       "   'ttft': {'mean': '21.44959869s'},\n",
       "   'itl': {'mean': '158.817814ms'},\n",
       "   'prompt_tokens': 22360477,\n",
       "   'cached_prompt_tokens': 0,\n",
       "   'completion_tokens': 2251149,\n",
       "   'total_tokens': 24611626}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "i = 0\n",
    "for spec in specs:\n",
    "    for bench in benches:\n",
    "        print(f\"{bench=}, {spec=}\")\n",
    "        try:\n",
    "            model = deepcopy(base_model)\n",
    "            model[\"spec\"].update(spec)\n",
    "            model_name = model.get(\"metadata\").get(\"name\")\n",
    "            model_replicas = model.get(\"spec\").get(\"minReplicas\")\n",
    "\n",
    "            !kubectl delete pod -l app.kubernetes.io/instance=kubeai\n",
    "            # Start a fresh instance of the benchmark Pod.\n",
    "            # !kubectl apply -f ./bench-pod.yaml\n",
    "            # This indicates using native K8s Service instead of KubeAI\n",
    "            if not \"loadBalancing\" in spec:\n",
    "                svc = create_k8s_service(model_name)\n",
    "                benchmark_pod_spec[\"spec\"][\"containers\"][0][\"env\"][0][\"value\"] = (\n",
    "                    f\"http://{svc.metadata.name}/v1\"\n",
    "                )\n",
    "            created_pod = v1.create_namespaced_pod(namespace=namespace, body=benchmark_pod_spec)\n",
    "\n",
    "            !kubectl wait pod --timeout 10m --for=condition=Ready -l app.kubernetes.io/instance=kubeai\n",
    "            !kubectl wait --timeout 10m --for=condition=Ready pod/{benchmark_pod_spec[\"metadata\"][\"name\"]}\n",
    "\n",
    "            #model[\"metadata\"][\"name\"] = model[\"metadata\"][\"name\"] + f'-{i}'\n",
    "            #models_client.create(body=model)\n",
    "            models_client.patch(\n",
    "                body=model,\n",
    "                content_type=\"application/apply-patch+yaml\",\n",
    "                field_manager=\"benchmark\",\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            !kubectl wait --timeout 30m --for=jsonpath='.status.replicas.ready'={model_replicas} model/{model_name}\n",
    "\n",
    "            thread_count = bench.get(\"thread_count\")\n",
    "            max_concurrent_threads = bench.get(\"max_concurrent_threads\")\n",
    "            cmd = f'kubectl exec bench -- bench --threads=./data/large-exact.json --thread-count={thread_count} --max-concurrent-threads={max_concurrent_threads} --request-model={model_name} --max-completion-tokens=40 --request-timeout=2m --seed=2 --format=json'\n",
    "            print(cmd)\n",
    "\n",
    "            output = run(cmd, shell=True, stdout=PIPE, encoding='utf8')\n",
    "            result = json.loads(output.stdout)\n",
    "            print(result)\n",
    "            all_results.append({\n",
    "                \"spec\": spec,\n",
    "                \"bench\": bench,\n",
    "                \"result\": result\n",
    "            }) \n",
    "        finally:\n",
    "            if not \"loadBalancing\" in spec:\n",
    "                v1.delete_namespaced_service(namespace=namespace, name=f\"k8s-{model_name}\")\n",
    "            models_client.delete(name=model_name, namespace=\"default\")\n",
    "            !kubectl delete --now pod/{benchmark_pod_spec[\"metadata\"][\"name\"]}\n",
    "            i+=1\n",
    "\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conccurency: 300 \"Strategy PrefixHash: TTFT=128.475449ms ITL=72.25189ms TPS(total)=41521.1349580028\n",
      "Conccurency: 600 \"Strategy PrefixHash: TTFT=205.630098ms ITL=100.67815ms TPS(total)=56932.5630554215\n",
      "Conccurency: 1200 \"Strategy PrefixHash: TTFT=386.049694ms ITL=151.420324ms TPS(total)=71811.59240452346\n",
      "Conccurency: 2400 \"Strategy PrefixHash: TTFT=12.581182145s ITL=209.408459ms TPS(total)=42032.4819209684\n",
      "Conccurency: 300 \"Strategy LeastLoad: TTFT=211.513933ms ITL=76.923279ms TPS(total)=38004.916490577125\n",
      "Conccurency: 600 \"Strategy LeastLoad: TTFT=319.854104ms ITL=107.296883ms TPS(total)=52380.64040492846\n",
      "Conccurency: 1200 \"Strategy LeastLoad: TTFT=1.196032821s ITL=166.676473ms TPS(total)=59273.60660429701\n",
      "Conccurency: 2400 \"Strategy LeastLoad: TTFT=12.912108233s ITL=245.956753ms TPS(total)=39866.51013796651\n",
      "Conccurency: 300 \"Strategy k8s-native: TTFT=126.940244ms ITL=83.082534ms TPS(total)=36395.055444493744\n",
      "Conccurency: 600 \"Strategy k8s-native: TTFT=2.264357412s ITL=115.110403ms TPS(total)=34654.71368886544\n",
      "Conccurency: 1200 \"Strategy k8s-native: TTFT=8.481505257s ITL=140.334721ms TPS(total)=31625.46865818341\n",
      "Conccurency: 2400 \"Strategy k8s-native: TTFT=21.44959869s ITL=158.817814ms TPS(total)=27507.218794463235\n"
     ]
    }
   ],
   "source": [
    "for r in all_results:\n",
    "    print(f'Conccurency: {r[\"bench\"][\"max_concurrent_threads\"]} \"Strategy {r[\"spec\"].get(\"loadBalancing\", {}).get(\"strategy\", \"k8s-native\")}: TTFT={r[\"result\"][\"ttft\"][\"mean\"]} ITL={r[\"result\"][\"itl\"][\"mean\"]} TPS(total)={r[\"result\"][\"run_total_throughput\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"8-replicas.json\", \"w\") as file:\n",
    "    json.dump(all_results, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def parse_time(time_str):\n",
    "    if time_str.endswith(\"ms\"):\n",
    "        return float(time_str[:-2]) / 1000.0\n",
    "    elif time_str.endswith(\"s\"):\n",
    "        return float(time_str[:-1])\n",
    "    else:\n",
    "        return float(time_str)\n",
    "\n",
    "parse_time(\"2s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(results):\n",
    "    data_by_strategy = {}\n",
    "    for res in results:\n",
    "        bench = res['bench']\n",
    "        max_threads = bench['max_concurrent_threads']\n",
    "        ttft_str = res['result']['ttft']['mean']\n",
    "        ttft_sec = parse_time(ttft_str)\n",
    "\n",
    "        # Get the load balancing strategy; use \"K8s - Service\" if not defined.\n",
    "        strategy = res.get('spec', {}).get('loadBalancing', {}).get('strategy', 'K8s Service')\n",
    "        if strategy != \"K8s Service\":\n",
    "            strategy = f\"KubeAI {strategy}\"\n",
    "\n",
    "        if strategy not in data_by_strategy:\n",
    "            data_by_strategy[strategy] = {\"max_threads\": [], \"ttft\": []}\n",
    "        data_by_strategy[strategy][\"max_threads\"].append(max_threads)\n",
    "        data_by_strategy[strategy][\"ttft\"].append(ttft_sec)\n",
    "\n",
    "    # Convert the grouped data into a mapping for easier lookup:\n",
    "    # strategy -> {max_concurrent_threads: ttft_sec}\n",
    "    data_mapping = {}\n",
    "    for strategy, data in data_by_strategy.items():\n",
    "        data_mapping[strategy] = dict(zip(data[\"max_threads\"], data[\"ttft\"]))\n",
    "\n",
    "    # Get the sorted unique max_concurrent_threads values across all groups.\n",
    "    unique_x = sorted(set(\n",
    "        max_thread \n",
    "        for data in data_by_strategy.values() \n",
    "        for max_thread in data[\"max_threads\"]\n",
    "    ))\n",
    "\n",
    "    # Setup for a grouped bar chart.\n",
    "    num_strategies = len(data_mapping)\n",
    "    bar_width = 0.8 / num_strategies  # total width per group = 0.8\n",
    "    x_indices = np.arange(len(unique_x))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, (strategy, mapping) in enumerate(data_mapping.items()):\n",
    "        # Retrieve ttft values for each unique max_concurrent_threads (default to 0 if not present)\n",
    "        y_values = [mapping.get(x, 0) for x in unique_x]\n",
    "        # Shift each strategy's bars for a grouped effect.\n",
    "        bars = plt.bar(x_indices + i * bar_width, y_values, width=bar_width, label=strategy)\n",
    "        # Annotate each bar with its height (i.e. TTFT value)\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, height,\n",
    "                     f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.xlabel(\"Max Concurrent Threads\")\n",
    "    plt.ylabel(\"Mean Time To First Token (s)\")\n",
    "    plt.title(\"Mean TTFT by Load Balancing Method (lower is better)\")\n",
    "    plt.xticks(x_indices + bar_width * (num_strategies - 1) / 2, unique_x)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()\n",
    "\n",
    "# Seems a pod failure happened with 2400 concurrency so removing invalid results.\n",
    "filtered_data = list(filter(lambda item: item.get(\"bench\")['max_concurrent_threads'] != 2400, all_results))\n",
    "filtered_data.reverse()\n",
    "plot(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
