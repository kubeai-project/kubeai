all:
  # Enable all models instead of enabling them one-by-one via .catalog.<name>.enabled
  enabled: false

catalog:
  # Mistral #
  e5-mistral-7b-instruct-cpu:
    enabled: false
    features: ["TextEmbedding"]
    owner: intfloat
    url: "hf://intfloat/e5-mistral-7b-instruct"
    engine: VLLM
    resourceProfile: cpu:1
    args:
    - --gpu-memory-utilization=0.9
  # Gemma #
  gemma2-2b-cpu:
    enabled: false
    features: ["TextGeneration"]
    owner: google
    url: "ollama://gemma2:2b"
    engine: OLlama
    resourceProfile: cpu:2
  # Llama #
  llama-3.1-8b-instruct-cpu:
    enabled: false
    features: ["TextGeneration"]
    owner: "meta-llama"
    url: "hf://meta-llama/Meta-Llama-3.1-8B-Instruct"
    engine: VLLM
    resourceProfile: cpu:6
    env:
      VLLM_CPU_KVCACHE_SPACE: "4"
    args:
    - --max-model-len=32768
    - --max-num-batched-token=32768
  llama-3.1-8b-instruct-fp8-l4:
    enabled: false
    features: ["TextGeneration"]
    owner: "neuralmagic"
    url: "hf://neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8"
    engine: VLLM
    resourceProfile: nvidia-gpu-l4:1
    args:
    - --max-model-len=16384
    - --max-num-batched-token=16384
    - --gpu-memory-utilization=0.9
    - --disable-log-requests
  llama-3.1-70b-instruct-fp8-h100:
    enabled: false
    features: [TextGeneration]
    url: hf://neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8
    engine: VLLM
    args:
      - --max-model-len=65536
      - --max-num-batched-token=65536
      - --gpu-memory-utilization=0.9
      - --tensor-parallel-size=2
      - --enable-prefix-caching
      - --disable-log-requests
    resourceProfile: nvidia-gpu-h100:2
    targetRequests: 500
  nomic-embed-text-cpu:
    enabled: false
    features: ["TextEmbedding"]
    owner: nomic
    url: "ollama://nomic-embed-text"
    engine: OLlama
    resourceProfile: cpu:1
  bge-embed-text-cpu:
    enabled: false
    features: ["TextEmbedding"]
    owner: baai
    url: "hf://BAAI/bge-small-en-v1.5"
    engine: Infinity
    resourceProfile: cpu:1
  # Opt #
  opt-125m-cpu:
    enabled: false
    features: ["TextGeneration"]
    owner: facebook
    url: "hf://facebook/opt-125m"
    engine: VLLM
    resourceProfile: cpu:1
  opt-125m-l4:
    enabled: false
    features: ["TextGeneration"]
    owner: facebook
    url: "hf://facebook/opt-125m"
    engine: VLLM
    resourceProfile: nvidia-gpu-l4:1
  # Qwen #
  qwen2-500m-cpu:
    enabled: false
    features: ["TextGeneration"]
    owner: alibaba
    url: "ollama://qwen2:0.5b"
    engine: OLlama
    resourceProfile: cpu:1
  faster-whisper-medium-en-cpu:
    enabled: false
    features: ["SpeechToText"]
    owner: Systran
    url: "hf://Systran/faster-whisper-medium.en"
    engine: FasterWhisper
    resourceProfile: cpu:1
