secretNames:
  huggingface: huggingface
modelServers:
  vLLM:
    images:
      default: "vllm/vllm-openai:latest"
      cpu: "us-central1-docker.pkg.dev/substratus-dev/default/vllm-cpu:v0.5.4-118-gfc93e561"
  ollama:
    images:
      default: "ollama/ollama:latest"
      cpu: "ollama/ollama:0.3.8"
messaging:
  errorMaxBackoff: 30s
  streams: []
  #- requestsURL: gcppubsub://projects/substratus-dev/subscriptions/test-kubeai-requests-sub
  #  responsesURL: gcppubsub://projects/substratus-dev/topics/test-kubeai-responses
  #  maxHandlers: 1
resourceProfiles:
  cpu:
    requests:
      cpu: 1
      memory: 2Gi
  nvidia-gpu-l4:
    limits:
      nvidia.com/gpu: "1"
    requests:
      nvidia.com/gpu: "1"
      cpu: "6"
      memory: "24Gi"

allowPodAddressOverride: true