apiVersion: kubeai.org/v1
kind: Model
metadata:
  name: dev
  annotations:
    # Have the controller send requests to localhost to allow for
    # running the controller locally (assuming a port-forward is in place).
    model-pod-ip: "127.0.0.1"
    model-pod-port: "7000" 
spec:
  features: [TextGeneration]
  owner: meta-llama
  url: hf://TinyLlama/TinyLlama-1.1B-Chat-v0.3
  adapters:
  - id: test
    url: hf://jashing/tinyllama-colorist-lora
  engine: VLLM
  resourceProfile: nvidia-gpu-l4:1
  minReplicas: 1
---
apiVersion: v1
kind: Service
metadata:
  name: dev-model
spec:
  selector:
    model: dev
  ports:
    - protocol: TCP
      port: 7000
      targetPort: 8000